---
title: "CPU缓存行和伪共享"
date: 2018-08-03T19:22:21+08:00
draft: false
tags: ["os"]
categories: ["os"]
---

## 缓存

CPU缓存(CPU Cache)可以有效提高访问内存的效率，CPU由多级缓存，如L1、L2、L3，分别表示一级缓存、二级缓存、三级缓存。

- L1容量最小，速度最快，又分为数据缓存L1d和指令缓存L1i，每个核都有L1缓存。
- L2容量比L1大，速度比L1慢，每个核都有L2缓存。
- L3容量最大，速度最慢，被单个插槽上的所有CPU核共享。
- 主存，由全部插槽上的所有CPU核共享。

CPU访问不同层级数据的大概时间：

| 从CPU到      	| 大约需要的CPU时钟周期| 大约需要的时间|   
| ------------- |:---------------:| -----------------:|
| 主存		| 	          | 约60-80ns	 |
| QPI总线传输	|		  | 约20ns        |   
| L3 Cache	| 约40-45 cycles  | 约15ns	|
| L2 Cache	| 约10 cycles 	  | 约3ns	|
| L1 Cache	| 约3-4 cycles	  | 约1ns	|
| 寄存器	| 1 cycle	  | |

## 缓存行

Cache Line可以简单理解为CPU Cache中的最小缓存单位。缓存行是2的整数幂个连续字节，一般为32-256个字节。最常见的缓存行大小是64个字节。可通过getconf -a | grep CACHE命令查看缓存相关信息。

缓存行有效地引用主内存中的一块地址。例如long类型是8字节，如果访问一个long数组，当数组中的一个值被加载到缓存中，它会额外加载另外7个，以致能非常快地遍历这个数组。事实上，它可以非常快速的遍历在连续的内存块中分配的任意数据结构。而如果在数据结构中的项在内存中不是彼此相邻的(如链表)，将得不到免费缓存加载所带来的优势，并且在这些数据结构中的每一个项都可能会出现缓存未命中。

## 伪共享

当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。

比如，在核心1上运行的线程想更新变量X，同时核心2上的线程想要更新变量Y。不幸的是，这两个变量在同一个缓存行中。每个线程都要去竞争缓存行的所有权来更新变量。如果核心1获得了所有权，缓存子系统将会使核心2中对应的缓存行失效。当核心2获得了所有权然后执行更新操作，核心1就要使自己对应的缓存行失效。这会来来回回的经过L3缓存，大大影响了性能。如果互相竞争的核心位于不同的插槽，就要额外横跨插槽连接，问题可能更加严重。

避免伪共享，可以通过缓存行填充的方式，来避免不同线程操作的对象对于不同的缓存行。

```
struct fifo {
    volatile uint32_t write;
    uint32_t wr_res[15];
    
    volatile uint32_t read;
    uint32_t rd_res[15];
    
    uint32_t size;
    uint32_t mask;
    uint32_t res[14];
    
    char data[0];
};
```
