---
title: "学习分布式系统"
date: 2019-12-18T19:22:21+08:00
draft: false
tags: ["distributed"]
categories: ["distributed"]
---

## 前言

最近在看关于分布式系统的相关知识，对此作一些总结整理，以便加深理解和更系统的进行学习。

## 概念

分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是利用更多的机器，处理更多的数据。

分布式系统主要是分布式计算与分布式存储。

## CAP理论

CAP理论，指的是在一个分布式系统中，Consistency(一致性)、 Availability(可用性)、Partition tolerance(分区容错性)，最多满足其中的两者。

- 一致性(C)：在分布式系统中的所有数据备份，在同一时刻是否同样的值。
- 可用性(A)：是指系统提供的服务一直处于可用状态，对于用户的请求可即时响应。
- 分区容忍性(P)：指的分布式系统中的某个节点或者网络分区出现了故障的时候，整个系统仍然能对外提供满足一致性和可用性的服务。也就是说部分故障不影响整体使用。

这里用一张图来做总结归纳:

![Local Picture](/images/distributed/distributed/cap.png "cap")


## 数据分片

数据分片，就是按照一定的规则将数据集划分成相互独立正交的数据子集，然后将数据子集分布到不同的节点上。

数据分片常有三种方式：hash方式，一致性hash(consistent hash)，按照数据范围(range based)。

__hash方式__

按照数据的某一特征来计算哈希值，并将哈希值与系统中的节点建立映射关系，从而将哈希值不同的数据分布到不同的节点上。

缺点是当加入或者删除一个节点时，需要大量的移动数据。

__一致性hash__

一致性hash是将数据按照特征值映射到一个首尾相接的hash环上，同时也将节点（按照IP地址或者机器名hash）映射到这个环上。对于数据，从数据在环上的位置开始，顺时针找到的第一个节点即为数据的存储节点。

这里举例说明，假设id的范围为[0, 1000]，N0,N1,N2在环上的位置分别是100, 400, 800，那么hash环示意图与数据的分布如下：

![Local Picture](/images/distributed/distributed/consistenthash_p1.png "consistenthash_p1") ![Local Picture](/images/distributed/distributed/consistenthash_p2.png "consistenthash_p2")

一致性hash在增加或者删除节点的时候，受到影响的数据是比较有限的，比如这里增加一个节点N3，其在环上的位置为600，因此，原来N2负责的范围段(400, 800]现在由N3(400, 600] N2(600, 800]负责，因此只需要将记录R7(id:533)从N2，迁移到N3。 

不难发现一致性hash方式在增删的时候只会影响到hash环上相邻的节点，不会发生大规模的数据迁移。

但是，一致性hash方式在增加节点的时候，只能分摊一个已存在节点的压力；同样，在其中一个节点挂掉的时候，该节点的压力也会被全部转移到下一个节点。而更好的情况是，需要在增删节点的时候，已存在的所有节点都能参与响应，以达到新的均衡状态。

因此，在实际工程中，一般会引入虚拟节点(virtual node)的概念。即不是将物理节点映射在hash换上，而是将虚拟节点映射到hash环上。虚拟节点的数目远大于物理节点，因此一个物理节点需要负责多个虚拟节点的真实存储。操作数据的时候，先通过hash环找到对应的虚拟节点，再通过虚拟节点与物理节点的映射关系找到对应的物理节点。

__range based__

简单来说，就是按照关键值划分成不同的区间，每个物理节点负责一个或者多个区间。其实这种方式跟一致性hash有点像，可以理解为物理节点在hash环上的位置是动态变化的。

还是举例说明，三个节点的数据区间分别是N0(0, 200], N1(200, 500], N2(500, 1000]。那么数据分布如下：

![Local Picture](/images/distributed/distributed/rangebased.png "rangebased")

注意，区间的大小不是固定的，每个数据区间的数据量与区间的大小也是没有关系的。比如说，一部分数据非常集中，那么区间大小应该是比较小的，即以数据量的大小为片段标准。在实际工程中，一个节点往往负责多个区间，每个区间成为一个块(chunk、block)，每个块有一个阈值，当达到这个阈值之后就会分裂成两个块。这样做的目的在于当有节点加入的时候，可以快速达到均衡的目的。

可以发现，如果一个节点负责的数据只有一个区间，range based与没有虚拟节点概念的一致性hash很类似；如果一个节点负责多个区间，range based与有虚拟节点概念的一致性hash很类似。

__对比总结__

| 方式          | 映射难度  | 元数据        | 节点增删      | 动态均衡      |
| ------------- |:---------:|:-------------:|:-------------:|:-------------:|
| hash          | 简单      | 非常简单，几乎不用修改 | 需要迁移的数据比较多 | 不支持 |
| consistent hash | 简单    | 比较简单，取决于节点规模，几乎不用修改 | 增删节点的时候只影响hash环上相邻节点，但不能使所有节点都参与数据迁移过程 | 不支持 |
| consistent hash(with virtual node) | 中等 | 稍微复杂一些，主要取决于虚拟节点规模，很少修改 | 需要迁移的数据比较少，且所有节点都能贡献部分数据 | 若支持(修改虚拟节点与物理节点映射关系) |
| range based   | 较为复杂  | 取决于每个块的大小，一般来说规模较大；且修改频率较高 | 需要迁移的数据比较少，且所有节点都能贡献部分数据 | 支持，且比较容易 |


## 数据冗余

在分布式系统中，节点存在出现故障的状况，比如断电、网络不可用、磁盘损坏等等，这些故障导致服务不可用。为了避免单点故障，可行的办法就是数据冗余，即将同一份数据放在不同的物理节点，甚至是不同的数据中心，以保证服务的高可用性和可靠性。


数据冗余方案可分为两类：一类是副本冗余方案，另一类是纠删码方案。

__副本冗余策略__

分布式存储系统中，冗余副本技术是一种最常用的分布式数据管理机制。副本冗余方案也称为数据复制方案，是指将系统中的各个数据块复制为多份并保存在不同的地方。这样当某个节点失效导致存储在该节点上的数据不可用时，仍然可以访问存储在别处的数据块来获取相应的信息。副本的数目越多，整个系统越可靠，但是副本数量的增加势必增加额外的系统资源消耗如存储空间，比如一个原始数据块的大小是1GB，采用数据复制方案，每个数据块复制k份，那么存储系统就需要消耗kGB的存储空间。一般的存储系统很难支撑如此大的存储开支。副本冗余策略简单易用，因此应用广泛。但是其消耗存储空间过大的缺点限制了其的使用。当前对副本冗余方案的研究主要在如何实现各个副本一致性方面。

__纠删码策略__

纠删码是另一种重要的数据冗余方案。纠删码方案的基本思想是，首先将原始数据分为k份，然后在对k份数据进行编码，得到另外n-k份数据，然后将总共为n份的数据发给不同的节点。在这n份数据中，只要其中任意的k份数据，就可以解析出原始数据。

从纠删码基本的形态来看，它是k个数据块加上m个校验块的结构，其中数据和校验的k和m值都能够按照一定的规则设定。在1～m个数据块(无论数据或校验块)损坏的情况下，整体数据仍然可以通过剩余数据块上的数据进行解析，得到整体数据，从而使整体数据不会丢失，存储系统仍然可以使用。也就是说一定数量的节点失效并不会造成用户数据的丢失。

__二者比较__

在同等可靠性的情况下，相比副本方案，纠删码方案将极大地减少数据的存储空间。尤其是在大量数据时，采用纠删码策略所节省的存储空间是很可观的。但是，存储系统需要花费极大开销对失效的数据进行及时修复，而采用副本冗余策略的存储系统在修复时所需要的资源远远小于采用纠删码策略的存储系统。两种策略都有各自的优缺点，副本冗余策略需要更多的存储空间，而纠删码策略需要更大的通信维护量和计算量。


## 副本控制协议

分布式系统中对复杂的问题之一: 副本的一致性问题，即从系统外部读取系统内部各个副本间的数据在一定的约束条件下是一致的。而副本控制协议按特定的协议流程控制副本数据的读写行为，使得副本满足一定的可用性和一致性要求的分布式协议。

副本控制协议分为两类：中心化副本控制协议和去中心化副本控制协议。

__中心化副本控制协议__

由一个中心节点协调副本数据的更新、维护副本之间的一致性。
- 优点：协议相对简单，所有副本相关的控制交由中心节点完成。
- 缺点：系统的可用性依赖于中心化节点，当中心节点异常或者中心节点通信中断时，系统将失去某些服务。

中心化副本控制协议主要有primary-secondary协议、2PC、MVCC。

primary-secondary又称为primary-backup，在协议中副本被分为两类，有且只有一个primary副本，其他的全部是secondary副本。

primary-secondary包括以下四大内容：数据更新流程、数据读取方式、Primary副本的确定和切换、数据同步。

a：数据更新流程
1. 数据更新都有primary节点协调完成。
2. 外部节点将更新操作发送给primary节点。
3. primary节点进行并发控制即确定并发更新操作的先后顺序。
4. primary节点将更新操作发送给secondary节点。
5. primary根据secondary节点的完成情况决定更新是否成功并将结果返回给外部节点。

b： 数据读取

如果只需要最终一致性，则读取任何副本都可以满足需求。如果需要会话一致性，则可以为副本设置版本号，每次更新后递增版本号，则用户读取副本时验证版本号，从而保证用户读到的数据都在会话范围内递增。想要最终一致性比较困难，由一下几种思路参考.
1. 只读primary节点。
2. 由primary控制节点secondary的可用性，更新成功为可用，更新不成功为不可用。
3. 基于Quorum机制。

c: primary副本的确定与切换

通常在primary-secondary类型的分布式系统中，哪个副本是Primary是属于元信息，由专门的元数据服务器维护。执行更新操作前先查询元数据管理服务器获取primary信息，再进行操作。
切换副本的难度在于两个方面：
1. 如何确定节点的状态以及发现原primary节点异常时一个较为复杂的问题。

   基于Lease机制(心跳机制)、基于Quorum机制(过半机制)。

2. 在原primary以及死机，如何确定一个secondary副本使得该副本上面的数据与原primary一致成为新的问题。

   由于分布式系统中可靠的发现节点异常需要一点的探测时间的，探测时间通常在10秒级别。 primary-secondary类型的分布式系统的最大缺点就是primary切换带来的一定时间的停服务时间。

d: 数据同步

通常的不一致情况:
1. 由于网络分化等异常，secondary上面的数据落后primary上的数据。
2. 在某些协议下面可能有脏数据，需要被丢弃。
3. secondary是新增的副本，完全没有数据，需要从其他副本拷贝数据。

解决方法
1. 常用的方法是回放primary上面的操作日志(通常是redo日志)，从而追上primary的更新进度。
2. 较好的方法就是在设计分布式协议不产生脏数据。也可以基于undo日志的方法删除脏数据。
3. 直接拷贝primary数据，或者使用快照。

__去中心化副本控制协议__

去中心化协议没有因为中心节点异常带来的停服务问题，缺点是协议过程通常比较复杂。

去中心化副本控制协议主要有：Paxos。

Paxos协议，该协议可以实现所有备份均可以提供对外服务，并且保证强一致性，通过理论和实践检验可以达到分布式的要求。Raft协议则是Paxos的一种特化，在这个协议的实现中，备份间需要区分主从角色，只有主节点可以提供对外服务，该协议实现简单高效，是工程实现中较好的选择。

